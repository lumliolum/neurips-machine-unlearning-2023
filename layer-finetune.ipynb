{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584cf5b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-16T18:59:36.557033Z",
     "iopub.status.busy": "2023-11-16T18:59:36.556603Z",
     "iopub.status.idle": "2023-11-16T18:59:40.585403Z",
     "shell.execute_reply": "2023-11-16T18:59:40.584640Z"
    },
    "papermill": {
     "duration": 4.0372,
     "end_time": "2023-11-16T18:59:40.587771",
     "exception": false,
     "start_time": "2023-11-16T18:59:36.550571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8309881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:59:40.597520Z",
     "iopub.status.busy": "2023-11-16T18:59:40.597089Z",
     "iopub.status.idle": "2023-11-16T18:59:40.649768Z",
     "shell.execute_reply": "2023-11-16T18:59:40.648932Z"
    },
    "papermill": {
     "duration": 0.059515,
     "end_time": "2023-11-16T18:59:40.651871",
     "exception": false,
     "start_time": "2023-11-16T18:59:40.592356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def parameter_count(model):\n",
    "    total_count = 0\n",
    "    trainable_count = 0\n",
    "    for p in model.parameters():\n",
    "        total_count += torch.prod(torch.tensor(p.shape)).item()\n",
    "        if p.requires_grad:\n",
    "            trainable_count += torch.prod(torch.tensor(p.shape)).item()\n",
    "\n",
    "    return total_count, trainable_count\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa37962f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:59:40.660589Z",
     "iopub.status.busy": "2023-11-16T18:59:40.660009Z",
     "iopub.status.idle": "2023-11-16T18:59:40.665779Z",
     "shell.execute_reply": "2023-11-16T18:59:40.664957Z"
    },
    "papermill": {
     "duration": 0.011953,
     "end_time": "2023-11-16T18:59:40.667552",
     "exception": false,
     "start_time": "2023-11-16T18:59:40.655599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MovingAverage:\n",
    "    def __init__(self, name, rd=4):\n",
    "        self.name = name\n",
    "        # avg value\n",
    "        self.val = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "        self.rd = rd\n",
    "\n",
    "    def update(self, x):\n",
    "        self.sum += x\n",
    "        self.count += 1\n",
    "\n",
    "        # update self.value\n",
    "        self.val = round(self.sum / self.count, self.rd)\n",
    "\n",
    "    def value(self) -> float:\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2ed9f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:59:40.675790Z",
     "iopub.status.busy": "2023-11-16T18:59:40.675439Z",
     "iopub.status.idle": "2023-11-16T18:59:40.682255Z",
     "shell.execute_reply": "2023-11-16T18:59:40.681474Z"
    },
    "papermill": {
     "duration": 0.012916,
     "end_time": "2023-11-16T18:59:40.684061",
     "exception": false,
     "start_time": "2023-11-16T18:59:40.671145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HiddenDataset(Dataset):\n",
    "    def __init__(self, df, base_dir):\n",
    "        super().__init__()\n",
    "        df['image_path'] = df['image_id'].apply(lambda x: os.path.join(base_dir,'images', x.split('-')[0], x.split('-')[1] + '.png'))\n",
    "        self.df = df\n",
    "\n",
    "        # read the images at the init only\n",
    "        # self.images = [\n",
    "        #    torch.tensor(np.transpose(np.array(Image.open(x).convert('RGB')), [2, 0, 1])) for x in self.df['image_path'].tolist()\n",
    "        # ]\n",
    "        self.images = [torchvision.io.read_image(x) for x in self.df['image_path'].tolist()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        age = self.df['age_group'].iloc[index]\n",
    "        return image, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c591f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:59:40.692471Z",
     "iopub.status.busy": "2023-11-16T18:59:40.691858Z",
     "iopub.status.idle": "2023-11-16T18:59:40.697783Z",
     "shell.execute_reply": "2023-11-16T18:59:40.697120Z"
    },
    "papermill": {
     "duration": 0.011929,
     "end_time": "2023-11-16T18:59:40.699594",
     "exception": false,
     "start_time": "2023-11-16T18:59:40.687665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n",
    "    # save the file while saving the version\n",
    "    # subprocess.run('touch submission.zip', shell=True)\n",
    "    base_dir = \"/kaggle/input/mock-cifar10-data\"\n",
    "    num_checkpoints = 10\n",
    "    real_run = False\n",
    "else:\n",
    "    # this part will run when we submit to kaggle.\n",
    "    base_dir = \"/kaggle/input/neurips-2023-machine-unlearning/\"\n",
    "    num_checkpoints = 512\n",
    "    real_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822b6b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:59:40.707766Z",
     "iopub.status.busy": "2023-11-16T18:59:40.707489Z",
     "iopub.status.idle": "2023-11-16T19:04:18.412680Z",
     "shell.execute_reply": "2023-11-16T19:04:18.411585Z"
    },
    "papermill": {
     "duration": 277.715532,
     "end_time": "2023-11-16T19:04:18.418753",
     "exception": false,
     "start_time": "2023-11-16T18:59:40.703221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the model\n",
      "Loading the model from checkpoint = /kaggle/input/mock-cifar10-data/original_model.pth\n",
      "Initializing the retain dataset\n",
      "Initializing the forget dataset\n",
      "Initializing the validation dataset\n",
      "length of retain dataset = 27440\n",
      "length of forget dataset = 560\n",
      "length of validation dataset = 3500\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Initializing the model\")\n",
    "model = resnet18(weights=None, num_classes=10)\n",
    "original_path = os.path.join(base_dir, 'original_model.pth')\n",
    "print(f\"Loading the model from checkpoint = {original_path}\")\n",
    "model.load_state_dict(torch.load(original_path))\n",
    "model.to(device)\n",
    "\n",
    "retain_df = pd.read_csv(os.path.join(base_dir, \"retain.csv\"))\n",
    "forget_df = pd.read_csv(os.path.join(base_dir, \"forget.csv\"))\n",
    "validation_df = pd.read_csv(os.path.join(base_dir, \"validation.csv\"))\n",
    "\n",
    "print(f\"Initializing the retain dataset\")\n",
    "retain_dataset = HiddenDataset(retain_df, base_dir)\n",
    "\n",
    "print(f\"Initializing the forget dataset\")\n",
    "forget_dataset = HiddenDataset(forget_df, base_dir)\n",
    "\n",
    "print(f\"Initializing the validation dataset\")\n",
    "validation_dataset = HiddenDataset(validation_df, base_dir)\n",
    "\n",
    "print(f\"length of retain dataset = {len(retain_dataset)}\")\n",
    "print(f\"length of forget dataset = {len(forget_dataset)}\")\n",
    "print(f\"length of validation dataset = {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ade6a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:04:18.428530Z",
     "iopub.status.busy": "2023-11-16T19:04:18.428142Z",
     "iopub.status.idle": "2023-11-16T19:04:18.441252Z",
     "shell.execute_reply": "2023-11-16T19:04:18.440402Z"
    },
    "papermill": {
     "duration": 0.020305,
     "end_time": "2023-11-16T19:04:18.443251",
     "exception": false,
     "start_time": "2023-11-16T19:04:18.422946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model_init, dataloader, device):\n",
    "    model_init.eval()\n",
    "    gt = np.array([])\n",
    "    pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "\n",
    "            out = model_init(X)\n",
    "            y_pred = torch.argmax(out, dim=1)\n",
    "\n",
    "            gt = np.append(gt, y.cpu().numpy())\n",
    "            pred = np.append(pred, y_pred.cpu().numpy())\n",
    "\n",
    "    acc = round(float(np.mean(gt == pred)), 6)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def unlearning(\n",
    "    model,\n",
    "    retain_loader,\n",
    "    forget_loader,\n",
    "    validation_loader,\n",
    "    device\n",
    "):\n",
    "    epochs = 1\n",
    "\n",
    "    # evaluate first\n",
    "    retain_acc = calculate_accuracy(model, retain_loader, device)\n",
    "    forget_acc = calculate_accuracy(model, forget_loader, device)\n",
    "    validation_acc = calculate_accuracy(model, validation_loader, device)\n",
    "\n",
    "    print(f\"Initial retain acc = {retain_acc}, forget acc = {forget_acc}, validation acc = {validation_acc}\")\n",
    "\n",
    "    # freeze the layers till fc\n",
    "#     for name, p in model.named_parameters():\n",
    "#         if \"fc\" not in name:\n",
    "#             p.requires_grad = False\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "    # set train\n",
    "    model.train()\n",
    "\n",
    "    # epoch\n",
    "    for X_retain, y_retain in retain_loader:\n",
    "        # change\n",
    "        X_retain = X_retain.float().to(device)\n",
    "        y_retain = y_retain.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_retain = model(X_retain)\n",
    "        loss = loss_fn(out_retain, y_retain)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # add noise\n",
    "    std = 1e-3\n",
    "    for p in model.parameters():\n",
    "        # 1e-4 is the standard deviation\n",
    "        noise = std * torch.randn_like(p.data)\n",
    "        p.data = p.data + noise\n",
    "\n",
    "    # evaluate now\n",
    "    retain_acc_update = calculate_accuracy(model, retain_loader, device)\n",
    "    forget_acc_update = calculate_accuracy(model, forget_loader, device)\n",
    "    validation_acc_update = calculate_accuracy(model, validation_loader, device)\n",
    "\n",
    "    print(f\"After scrub retain acc = {retain_acc_update}, forget acc = {forget_acc_update}, validation acc = {validation_acc_update}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c78cb5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:04:18.454434Z",
     "iopub.status.busy": "2023-11-16T19:04:18.453845Z",
     "iopub.status.idle": "2023-11-16T19:06:40.180701Z",
     "shell.execute_reply": "2023-11-16T19:06:40.179667Z"
    },
    "papermill": {
     "duration": 141.735519,
     "end_time": "2023-11-16T19:06:40.182879",
     "exception": false,
     "start_time": "2023-11-16T19:04:18.447360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for checkpoint = 0\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.995809, forget acc = 0.996429, validation acc = 0.744571\n",
      "Time taken = 18.838 seconds\n",
      "Running for checkpoint = 1\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997413, forget acc = 0.996429, validation acc = 0.750571\n",
      "Time taken = 13.749 seconds\n",
      "Running for checkpoint = 2\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997668, forget acc = 0.996429, validation acc = 0.749714\n",
      "Time taken = 13.715 seconds\n",
      "Running for checkpoint = 3\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997303, forget acc = 1.0, validation acc = 0.752\n",
      "Time taken = 13.635 seconds\n",
      "Running for checkpoint = 4\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.996757, forget acc = 0.996429, validation acc = 0.746286\n",
      "Time taken = 13.576 seconds\n",
      "Running for checkpoint = 5\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997449, forget acc = 0.998214, validation acc = 0.750286\n",
      "Time taken = 13.636 seconds\n",
      "Running for checkpoint = 6\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997413, forget acc = 0.998214, validation acc = 0.749429\n",
      "Time taken = 13.634 seconds\n",
      "Running for checkpoint = 7\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997449, forget acc = 0.996429, validation acc = 0.750571\n",
      "Time taken = 13.593 seconds\n",
      "Running for checkpoint = 8\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997012, forget acc = 0.996429, validation acc = 0.747714\n",
      "Time taken = 13.724 seconds\n",
      "Running for checkpoint = 9\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "After scrub retain acc = 0.997886, forget acc = 0.996429, validation acc = 0.749714\n",
      "Time taken = 13.615 seconds\n",
      "Total timetaken to run the 10 models is = 141.717 seconds\n"
     ]
    }
   ],
   "source": [
    "T1 = time.time()\n",
    "\n",
    "batch_size = 64\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for sd in range(num_checkpoints):\n",
    "    TS1 = time.time()\n",
    "    print(f\"Running for checkpoint = {sd}\")\n",
    "    final_model = copy.deepcopy(model)\n",
    "    unlearning(final_model, retain_loader, forget_loader, validation_loader, device)\n",
    "    # save it as half as there can be space issue.\n",
    "    # https://www.kaggle.com/competitions/neurips-2023-machine-unlearning/discussion/441758\n",
    "    # 32 precision model is 43MB and 16 precision model is 22MB. \n",
    "    state = final_model.half().state_dict()\n",
    "    torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{sd}.pth')\n",
    "    TS2 = time.time()\n",
    "    print(f\"Time taken = {round(TS2 - TS1, 3)} seconds\")\n",
    "\n",
    "T2 = time.time()\n",
    "timetaken_models = round(T2 - T1, 3)\n",
    "print(f\"Total timetaken to run the {num_checkpoints} models is = {timetaken_models} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b6ef56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:06:40.196316Z",
     "iopub.status.busy": "2023-11-16T19:06:40.195969Z",
     "iopub.status.idle": "2023-11-16T19:06:50.233854Z",
     "shell.execute_reply": "2023-11-16T19:06:50.232903Z"
    },
    "papermill": {
     "duration": 10.047261,
     "end_time": "2023-11-16T19:06:50.236049",
     "exception": false,
     "start_time": "2023-11-16T19:06:40.188788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/tmp/unlearned_checkpoint_0.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_1.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_2.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_3.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_4.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_5.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_6.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_7.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_8.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_9.pth (deflated 7%)\n",
      "Total time taken to zip the 10 models is = 10.032 seconds\n"
     ]
    }
   ],
   "source": [
    "T3 = time.time()\n",
    "# Ensure that submission.zip will contain exactly num_checkpoints \n",
    "# (if this is not the case, an exception will be thrown).\n",
    "unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "if len(unlearned_ckpts) != num_checkpoints:\n",
    "    raise RuntimeError(f'Expected exactly {num_checkpoints} checkpoints. The submission will throw an exception otherwise.')\n",
    "\n",
    "subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n",
    "T4 = time.time()\n",
    "zip_time_taken = round(T4 - T3, 3)\n",
    "print(f\"Total time taken to zip the {num_checkpoints} models is = {zip_time_taken} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c02d1",
   "metadata": {
    "papermill": {
     "duration": 0.006581,
     "end_time": "2023-11-16T19:06:50.249711",
     "exception": false,
     "start_time": "2023-11-16T19:06:50.243130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6535361,
     "sourceId": 56167,
     "sourceType": "competition"
    },
    {
     "sourceId": 150187083,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 439.625184,
   "end_time": "2023-11-16T19:06:52.740690",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-16T18:59:33.115506",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

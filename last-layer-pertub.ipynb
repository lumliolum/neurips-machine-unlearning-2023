{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1faf2bae",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-25T20:36:16.982709Z",
     "iopub.status.busy": "2023-11-25T20:36:16.982365Z",
     "iopub.status.idle": "2023-11-25T20:36:21.072214Z",
     "shell.execute_reply": "2023-11-25T20:36:21.071366Z"
    },
    "papermill": {
     "duration": 4.097537,
     "end_time": "2023-11-25T20:36:21.074511",
     "exception": false,
     "start_time": "2023-11-25T20:36:16.976974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a5f6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:36:21.084509Z",
     "iopub.status.busy": "2023-11-25T20:36:21.084089Z",
     "iopub.status.idle": "2023-11-25T20:36:21.151785Z",
     "shell.execute_reply": "2023-11-25T20:36:21.150913Z"
    },
    "papermill": {
     "duration": 0.074802,
     "end_time": "2023-11-25T20:36:21.154024",
     "exception": false,
     "start_time": "2023-11-25T20:36:21.079222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def parameter_count(model):\n",
    "    total_count = 0\n",
    "    trainable_count = 0\n",
    "    for p in model.parameters():\n",
    "        total_count += torch.prod(torch.tensor(p.shape)).item()\n",
    "        if p.requires_grad:\n",
    "            trainable_count += torch.prod(torch.tensor(p.shape)).item()\n",
    "\n",
    "    return total_count, trainable_count\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83a3f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:36:21.162568Z",
     "iopub.status.busy": "2023-11-25T20:36:21.162285Z",
     "iopub.status.idle": "2023-11-25T20:36:21.168408Z",
     "shell.execute_reply": "2023-11-25T20:36:21.167549Z"
    },
    "papermill": {
     "duration": 0.012656,
     "end_time": "2023-11-25T20:36:21.170382",
     "exception": false,
     "start_time": "2023-11-25T20:36:21.157726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MovingAverage:\n",
    "    def __init__(self, name, rd=4):\n",
    "        self.name = name\n",
    "        # avg value\n",
    "        self.val = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "        self.rd = rd\n",
    "\n",
    "    def update(self, x):\n",
    "        self.sum += x\n",
    "        self.count += 1\n",
    "\n",
    "        # update self.value\n",
    "        self.val = round(self.sum / self.count, self.rd)\n",
    "\n",
    "    def value(self) -> float:\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d8f4bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:36:21.178863Z",
     "iopub.status.busy": "2023-11-25T20:36:21.178585Z",
     "iopub.status.idle": "2023-11-25T20:36:21.185451Z",
     "shell.execute_reply": "2023-11-25T20:36:21.184658Z"
    },
    "papermill": {
     "duration": 0.013275,
     "end_time": "2023-11-25T20:36:21.187337",
     "exception": false,
     "start_time": "2023-11-25T20:36:21.174062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HiddenDataset(Dataset):\n",
    "    def __init__(self, df, base_dir):\n",
    "        super().__init__()\n",
    "        df['image_path'] = df['image_id'].apply(lambda x: os.path.join(base_dir,'images', x.split('-')[0], x.split('-')[1] + '.png'))\n",
    "        self.df = df\n",
    "\n",
    "        # read the images at the init only\n",
    "        # self.images = [\n",
    "        #    torch.tensor(np.transpose(np.array(Image.open(x).convert('RGB')), [2, 0, 1])) for x in self.df['image_path'].tolist()\n",
    "        # ]\n",
    "        self.images = [torchvision.io.read_image(x) for x in self.df['image_path'].tolist()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        age = self.df['age_group'].iloc[index]\n",
    "        return image, age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c198e627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:36:21.195878Z",
     "iopub.status.busy": "2023-11-25T20:36:21.195616Z",
     "iopub.status.idle": "2023-11-25T20:36:21.201393Z",
     "shell.execute_reply": "2023-11-25T20:36:21.200736Z"
    },
    "papermill": {
     "duration": 0.012076,
     "end_time": "2023-11-25T20:36:21.203244",
     "exception": false,
     "start_time": "2023-11-25T20:36:21.191168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n",
    "    # save the file while saving the version\n",
    "    # subprocess.run('touch submission.zip', shell=True)\n",
    "    base_dir = \"/kaggle/input/mock-cifar10-data\"\n",
    "    num_checkpoints = 10\n",
    "    real_run = False\n",
    "else:\n",
    "    # this part will run when we submit to kaggle.\n",
    "    base_dir = \"/kaggle/input/neurips-2023-machine-unlearning/\"\n",
    "    num_checkpoints = 512\n",
    "    real_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ab017b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:36:21.212389Z",
     "iopub.status.busy": "2023-11-25T20:36:21.212119Z",
     "iopub.status.idle": "2023-11-25T20:38:46.634783Z",
     "shell.execute_reply": "2023-11-25T20:38:46.633877Z"
    },
    "papermill": {
     "duration": 145.429618,
     "end_time": "2023-11-25T20:38:46.636865",
     "exception": false,
     "start_time": "2023-11-25T20:36:21.207247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the model\n",
      "Loading the model from checkpoint = /kaggle/input/mock-cifar10-data/original_model.pth\n",
      "Initializing the retain dataset\n",
      "Initializing the forget dataset\n",
      "Initializing the validation dataset\n",
      "length of retain dataset = 27440\n",
      "length of forget dataset = 560\n",
      "length of validation dataset = 3500\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "\n",
    "print(f\"Initializing the model\")\n",
    "trained_model = resnet18(weights=None, num_classes=10)\n",
    "original_path = os.path.join(base_dir, 'original_model.pth')\n",
    "print(f\"Loading the model from checkpoint = {original_path}\")\n",
    "trained_model.load_state_dict(torch.load(original_path, map_location=device))\n",
    "trained_model.to(device)\n",
    "\n",
    "retain_df = pd.read_csv(os.path.join(base_dir, \"retain.csv\"))\n",
    "forget_df = pd.read_csv(os.path.join(base_dir, \"forget.csv\"))\n",
    "validation_df = pd.read_csv(os.path.join(base_dir, \"validation.csv\"))\n",
    "\n",
    "print(f\"Initializing the retain dataset\")\n",
    "retain_dataset = HiddenDataset(retain_df, base_dir)\n",
    "# retain_dataset = HiddenDataset(forget_df, base_dir)\n",
    "\n",
    "print(f\"Initializing the forget dataset\")\n",
    "forget_dataset = HiddenDataset(forget_df, base_dir)\n",
    "\n",
    "print(f\"Initializing the validation dataset\")\n",
    "validation_dataset = HiddenDataset(validation_df, base_dir)\n",
    "\n",
    "print(f\"length of retain dataset = {len(retain_dataset)}\")\n",
    "print(f\"length of forget dataset = {len(forget_dataset)}\")\n",
    "print(f\"length of validation dataset = {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad7425a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:38:46.647411Z",
     "iopub.status.busy": "2023-11-25T20:38:46.647104Z",
     "iopub.status.idle": "2023-11-25T20:38:46.654117Z",
     "shell.execute_reply": "2023-11-25T20:38:46.653183Z"
    },
    "papermill": {
     "duration": 0.014673,
     "end_time": "2023-11-25T20:38:46.656221",
     "exception": false,
     "start_time": "2023-11-25T20:38:46.641548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copied from : https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, tm):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.trained_model = tm\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trained_model.conv1(x)\n",
    "        x = self.trained_model.bn1(x)\n",
    "        x = self.trained_model.relu(x)\n",
    "        x = self.trained_model.maxpool(x)\n",
    "\n",
    "        x = self.trained_model.layer1(x)\n",
    "        x = self.trained_model.layer2(x)\n",
    "        x = self.trained_model.layer3(x)\n",
    "        x = self.trained_model.layer4(x)\n",
    "\n",
    "        x = self.trained_model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # x will be of shape (batchsize, 512)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa597850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:38:46.666538Z",
     "iopub.status.busy": "2023-11-25T20:38:46.666281Z",
     "iopub.status.idle": "2023-11-25T20:38:46.803839Z",
     "shell.execute_reply": "2023-11-25T20:38:46.802992Z"
    },
    "papermill": {
     "duration": 0.145273,
     "end_time": "2023-11-25T20:38:46.805866",
     "exception": false,
     "start_time": "2023-11-25T20:38:46.660593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model_init, dataloader, device):\n",
    "    model_init.eval()\n",
    "    gt = np.array([])\n",
    "    pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "\n",
    "            out = model_init(X)\n",
    "            y_pred = torch.argmax(out, dim=1)\n",
    "\n",
    "            gt = np.append(gt, y.cpu().numpy())\n",
    "            pred = np.append(pred, y_pred.cpu().numpy())\n",
    "\n",
    "    acc = round(float(np.mean(gt == pred)), 6)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def frx(features, gt, params):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    alpha = params[:5120].view(10, 512)\n",
    "    beta = params[5120:].view(1, 10)\n",
    "    # features = (batch_size, 512), alphaT = (512, 10) , beta = (1, 10)\n",
    "    logits = torch.mm(features, torch.transpose(alpha, 0, 1)) + beta\n",
    "    # logits -> (512, 10), gt -> (512)\n",
    "    loss = loss_fn(logits, gt)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def unlearning(\n",
    "    model,\n",
    "    retain_loader,\n",
    "    forget_loader,\n",
    "    validation_loader,\n",
    "    device\n",
    "):\n",
    "    # evaluate first\n",
    "    retain_acc = calculate_accuracy(model, retain_loader, device)\n",
    "    forget_acc = calculate_accuracy(model, forget_loader, device)\n",
    "    validation_acc = calculate_accuracy(model, validation_loader, device)\n",
    "\n",
    "    print(f\"Initial retain acc = {retain_acc}, forget acc = {forget_acc}, validation acc = {validation_acc}\")\n",
    "\n",
    "    # add noise\n",
    "    std = 1e-3\n",
    "    for p in model.parameters():\n",
    "        noise = std * torch.randn_like(p.data)\n",
    "        p.data = p.data + noise\n",
    "\n",
    "    # create a model\n",
    "    mymodel = MyModel(copy.deepcopy(model))\n",
    "    mymodel.to(device)\n",
    "    # set it to eval\n",
    "    mymodel.eval()\n",
    "\n",
    "    # collect features retain\n",
    "    retain_features = []\n",
    "    retain_gt = []\n",
    "    with torch.no_grad():\n",
    "        for X_retain, y_retain in retain_loader:\n",
    "            # change\n",
    "            X_retain = X_retain.float().to(device)\n",
    "            y_retain = y_retain.long().to(device)\n",
    "            out_retain = mymodel(X_retain)\n",
    "            retain_features.append(out_retain)\n",
    "            retain_gt.append(y_retain)\n",
    "\n",
    "    retain_features = torch.cat(retain_features, dim=0)\n",
    "    retain_gt = torch.cat(retain_gt)\n",
    "    print(f\"retain features shape = {retain_features.shape}\")\n",
    "    print(f\"retain gt shape = {retain_gt.shape}\")\n",
    "\n",
    "    # collect features forget\n",
    "    forget_features = []\n",
    "    forget_gt = []\n",
    "    with torch.no_grad():\n",
    "        for X_forget, y_forget in forget_loader:\n",
    "            # change\n",
    "            X_forget = X_forget.float().to(device)\n",
    "            y_forget = y_forget.long().to(device)\n",
    "            out_forget = mymodel(X_forget)\n",
    "            forget_features.append(out_forget)\n",
    "            forget_gt.append(y_forget)\n",
    "\n",
    "    forget_features = torch.cat(forget_features, dim=0)\n",
    "    forget_gt = torch.cat(forget_gt)\n",
    "    print(f\"forget features shape = {forget_features.shape}\")\n",
    "    print(f\"forget gt shape = {forget_gt.shape}\")\n",
    "\n",
    "    # collect the param vector\n",
    "    print(f\"mean weight = {torch.mean(model.fc.weight.data)}, mean bias = {torch.mean(model.fc.bias.data)}\")\n",
    "    vfcat = torch.cat(\n",
    "        [model.fc.weight.data.view(-1, 1), model.fc.bias.data.view(-1, 1)],\n",
    "        dim=0\n",
    "    ).squeeze()\n",
    "\n",
    "    # create the partial function and calculate the retain hessian\n",
    "    retain_param = copy.deepcopy(vfcat)\n",
    "    retain_param.requires_grad = True\n",
    "    print(f\"retain parameter vector shape = {retain_param.shape}\")\n",
    "\n",
    "    retain_partial_frx = partial(frx, retain_features, retain_gt)\n",
    "    retain_hessian = torch.autograd.functional.hessian(retain_partial_frx, retain_param)\n",
    "    print(f\"retain hessian shape = {retain_hessian.shape}\")\n",
    "\n",
    "    # create the partial function and calculate the forget gradient\n",
    "    forget_param = copy.deepcopy(vfcat)\n",
    "    forget_param.requires_grad = True\n",
    "    print(f\"forget parameter vector shape = {forget_param.shape}\")\n",
    "\n",
    "    forget_partial_frx = partial(frx, forget_features, forget_gt)\n",
    "    forget_loss = frx(forget_features, forget_gt, forget_param)\n",
    "    forget_grad = torch.autograd.grad(forget_loss, forget_param)\n",
    "    print(f\"forget gradient shape = {forget_grad[0].shape}\")\n",
    "\n",
    "    # calculate the final param\n",
    "    eps = 1e-3\n",
    "    final_param = copy.deepcopy(vfcat)\n",
    "    pertub = torch.mm(torch.linalg.inv(retain_hessian), torch.unsqueeze(forget_grad[0], -1)).squeeze()\n",
    "    final_param = final_param + eps * pertub\n",
    "\n",
    "    # replace the final param as the model weight and bias\n",
    "    model.fc.weight.data = copy.deepcopy(final_param[:5120].view(10, 512))\n",
    "    model.fc.bias.data = copy.deepcopy(final_param[5120:].view(10))\n",
    "    print(f\"mean weight = {torch.mean(model.fc.weight.data)}, mean bias = {torch.mean(model.fc.bias.data)}\")\n",
    "\n",
    "    # evaluate now\n",
    "    retain_acc_update = calculate_accuracy(model, retain_loader, device)\n",
    "    forget_acc_update = calculate_accuracy(model, forget_loader, device)\n",
    "    validation_acc_update = calculate_accuracy(model, validation_loader, device)\n",
    "\n",
    "    print(f\"After scrub retain acc = {retain_acc_update}, forget acc = {forget_acc_update}, validation acc = {validation_acc_update}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db1541a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:38:46.816328Z",
     "iopub.status.busy": "2023-11-25T20:38:46.816039Z",
     "iopub.status.idle": "2023-11-25T20:40:53.759118Z",
     "shell.execute_reply": "2023-11-25T20:40:53.758161Z"
    },
    "papermill": {
     "duration": 126.957719,
     "end_time": "2023-11-25T20:40:53.768237",
     "exception": false,
     "start_time": "2023-11-25T20:38:46.810518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for checkpoint = 0\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012752010487020016, mean bias = -0.013015004806220531\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = 0.11834371089935303, mean bias = 11.994539260864258\n",
      "After scrub retain acc = 0.978972, forget acc = 0.980357, validation acc = 0.727429\n",
      "Time taken = 17.88 seconds\n",
      "Running for checkpoint = 1\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012746038846671581, mean bias = -0.012870565056800842\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.04629591107368469, mean bias = -2.5577645301818848\n",
      "After scrub retain acc = 0.981122, forget acc = 0.978571, validation acc = 0.728286\n",
      "Time taken = 12.088 seconds\n",
      "Running for checkpoint = 2\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.01275923103094101, mean bias = -0.012817680835723877\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.027914905920624733, mean bias = 0.12226202338933945\n",
      "After scrub retain acc = 0.97981, forget acc = 0.982143, validation acc = 0.726\n",
      "Time taken = 11.869 seconds\n",
      "Running for checkpoint = 3\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012763077393174171, mean bias = -0.013125630095601082\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.002793574472889304, mean bias = 3.670729875564575\n",
      "After scrub retain acc = 0.979337, forget acc = 0.978571, validation acc = 0.726857\n",
      "Time taken = 12.083 seconds\n",
      "Running for checkpoint = 4\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.01275667268782854, mean bias = -0.012891769409179688\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.10047286003828049, mean bias = -2.780818462371826\n",
      "After scrub retain acc = 0.978025, forget acc = 0.978571, validation acc = 0.727143\n",
      "Time taken = 12.076 seconds\n",
      "Running for checkpoint = 5\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012757538817822933, mean bias = -0.012966984882950783\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.05438883230090141, mean bias = -2.2770988941192627\n",
      "After scrub retain acc = 0.97777, forget acc = 0.980357, validation acc = 0.721429\n",
      "Time taken = 12.058 seconds\n",
      "Running for checkpoint = 6\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012765267863869667, mean bias = -0.012941782362759113\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.03947898745536804, mean bias = 0.7901520133018494\n",
      "After scrub retain acc = 0.979446, forget acc = 0.973214, validation acc = 0.724857\n",
      "Time taken = 12.15 seconds\n",
      "Running for checkpoint = 7\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012752554379403591, mean bias = -0.013320750556886196\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.03214607760310173, mean bias = -0.4883020520210266\n",
      "After scrub retain acc = 0.981487, forget acc = 0.982143, validation acc = 0.729429\n",
      "Time taken = 12.035 seconds\n",
      "Running for checkpoint = 8\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.01274962443858385, mean bias = -0.012715182267129421\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.005412507802248001, mean bias = 0.7955724000930786\n",
      "After scrub retain acc = 0.978499, forget acc = 0.983929, validation acc = 0.726\n",
      "Time taken = 12.193 seconds\n",
      "Running for checkpoint = 9\n",
      "Initial retain acc = 0.979701, forget acc = 0.985714, validation acc = 0.725714\n",
      "retain features shape = torch.Size([27440, 512])\n",
      "retain gt shape = torch.Size([27440])\n",
      "forget features shape = torch.Size([560, 512])\n",
      "forget gt shape = torch.Size([560])\n",
      "mean weight = -0.012735656462609768, mean bias = -0.012933313846588135\n",
      "retain parameter vector shape = torch.Size([5130])\n",
      "retain hessian shape = torch.Size([5130, 5130])\n",
      "forget parameter vector shape = torch.Size([5130])\n",
      "forget gradient shape = torch.Size([5130])\n",
      "mean weight = -0.07875833660364151, mean bias = 6.155943870544434\n",
      "After scrub retain acc = 0.980029, forget acc = 0.980357, validation acc = 0.728571\n",
      "Time taken = 12.097 seconds\n",
      "Total timetaken to run the 10 models is = 126.936 seconds\n"
     ]
    }
   ],
   "source": [
    "T1 = time.time()\n",
    "\n",
    "batch_size = 64\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for sd in range(num_checkpoints):\n",
    "    TS1 = time.time()\n",
    "    print(f\"Running for checkpoint = {sd}\")\n",
    "    final_model = copy.deepcopy(trained_model)\n",
    "    unlearning(final_model, retain_loader, forget_loader, validation_loader, device)\n",
    "    TS2 = time.time()\n",
    "    state = final_model.half().state_dict()\n",
    "    torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{sd}.pth')\n",
    "    print(f\"Time taken = {round(TS2 - TS1, 3)} seconds\")\n",
    "\n",
    "T2 = time.time()\n",
    "timetaken_models = round(T2 - T1, 3)\n",
    "print(f\"Total timetaken to run the {num_checkpoints} models is = {timetaken_models} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931d3de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:40:53.785035Z",
     "iopub.status.busy": "2023-11-25T20:40:53.784701Z",
     "iopub.status.idle": "2023-11-25T20:41:03.816548Z",
     "shell.execute_reply": "2023-11-25T20:41:03.815259Z"
    },
    "papermill": {
     "duration": 10.042538,
     "end_time": "2023-11-25T20:41:03.818581",
     "exception": false,
     "start_time": "2023-11-25T20:40:53.776043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/tmp/unlearned_checkpoint_0.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_1.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_2.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_3.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_4.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_5.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_6.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_7.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_8.pth (deflated 7%)\n",
      "  adding: kaggle/tmp/unlearned_checkpoint_9.pth (deflated 7%)\n",
      "Total time taken to zip the 10 models is = 10.026 seconds\n"
     ]
    }
   ],
   "source": [
    "T3 = time.time()\n",
    "# Ensure that submission.zip will contain exactly num_checkpoints \n",
    "# (if this is not the case, an exception will be thrown).\n",
    "unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "if len(unlearned_ckpts) != num_checkpoints:\n",
    "    raise RuntimeError(f'Expected exactly {num_checkpoints} checkpoints. The submission will throw an exception otherwise.')\n",
    "\n",
    "subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n",
    "T4 = time.time()\n",
    "zip_time_taken = round(T4 - T3, 3)\n",
    "print(f\"Total time taken to zip the {num_checkpoints} models is = {zip_time_taken} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e192253",
   "metadata": {
    "papermill": {
     "duration": 0.00848,
     "end_time": "2023-11-25T20:41:03.836047",
     "exception": false,
     "start_time": "2023-11-25T20:41:03.827567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff211ec",
   "metadata": {
    "papermill": {
     "duration": 0.008436,
     "end_time": "2023-11-25T20:41:03.853006",
     "exception": false,
     "start_time": "2023-11-25T20:41:03.844570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6535361,
     "sourceId": 56167,
     "sourceType": "competition"
    },
    {
     "sourceId": 150187083,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 292.662936,
   "end_time": "2023-11-25T20:41:06.241427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-25T20:36:13.578491",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
